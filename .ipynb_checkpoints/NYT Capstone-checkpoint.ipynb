{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Business Question\n",
    "\n",
    "The New York Times is reevaluating the comment moderation on its web content, in hopes of stimulating reader engagement, deepening the quality of user feedback, and identifying potentially problematic comments more quickly. They would like to use the existing recommendation tool to develop a machine learning model that will predict which comments will be most popular and which comments will be most likely to generate further engagement. The end goal will be to sort comments according to this prediction (as a third option available to users in addition to presenting comments ranked in response to recommendations or chronologically). Additionally, they would like to identify comments that are most likely to be flagged as abuse to bring these comments to the attention of moderators more quickly. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Acquisition\n",
    "The data used for this project represents articles and comments on The New York Times website in April 2017. I downloaded the dataset from Kaggle [at this address](https://www.kaggle.com/aashita/nyt-comments). The data was originally collected using the New York Times API. The process for this collection is well-documented on the Kaggle page. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "#from skmultilearn.problem_transform import ClassifierChain\n",
    "\n",
    "from sklearn.multioutput import ClassifierChain\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.probability import FreqDist\n",
    "\n",
    "#toggle variable to print previews, 'sanity checks'\n",
    "print_detail = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\carly\\anaconda3\\envs\\learn-env\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3145: DtypeWarning: Columns (25,26) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "# DELETE ME if you end up wanting to expand and add more data to the dataset, you can combine the datasets before this cell \n",
    "# and name them art/comm and then pick up at this point.\n",
    "\n",
    "# read in dataset of articles\n",
    "art = pd.read_csv('data/ArticlesApril2017.csv')\n",
    "# read in dataset of comments\n",
    "comm = pd.read_csv('data/CommentsApril2017.csv')\n",
    "\n",
    "if print_detail:\n",
    "    # preview\n",
    "    art.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "if print_detail:\n",
    "    #preview\n",
    "    comm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article columns: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['abstract', 'articleID', 'articleWordCount', 'byline', 'documentType',\n",
       "       'headline', 'keywords', 'multimedia', 'newDesk', 'printPage', 'pubDate',\n",
       "       'sectionName', 'snippet', 'source', 'typeOfMaterial', 'webURL'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comments columns: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['approveDate', 'commentBody', 'commentID', 'commentSequence',\n",
       "       'commentTitle', 'commentType', 'createDate', 'depth',\n",
       "       'editorsSelection', 'parentID', 'parentUserDisplayName', 'permID',\n",
       "       'picURL', 'recommendations', 'recommendedFlag', 'replyCount',\n",
       "       'reportAbuseFlag', 'sharing', 'status', 'timespeople', 'trusted',\n",
       "       'updateDate', 'userDisplayName', 'userID', 'userLocation', 'userTitle',\n",
       "       'userURL', 'inReplyTo', 'articleID', 'sectionName', 'newDesk',\n",
       "       'articleWordCount', 'printPage', 'typeOfMaterial'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Article columns: ')\n",
    "display(art.columns)\n",
    "print('Comments columns: ')\n",
    "display(comm.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine the article and comment dataframes using articleID as an index\n",
    "df = pd.merge(comm, art, on='articleID')\n",
    "\n",
    "if print_detail:\n",
    "    df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['approveDate', 'commentBody', 'commentID', 'commentSequence',\n",
       "       'commentTitle', 'commentType', 'createDate', 'depth',\n",
       "       'editorsSelection', 'parentID', 'parentUserDisplayName', 'permID',\n",
       "       'picURL', 'recommendations', 'recommendedFlag', 'replyCount',\n",
       "       'reportAbuseFlag', 'sharing', 'status', 'timespeople', 'trusted',\n",
       "       'updateDate', 'userDisplayName', 'userID', 'userLocation', 'userTitle',\n",
       "       'userURL', 'inReplyTo', 'articleID', 'sectionName_x', 'newDesk_x',\n",
       "       'articleWordCount_x', 'printPage_x', 'typeOfMaterial_x', 'abstract',\n",
       "       'articleWordCount_y', 'byline', 'documentType', 'headline', 'keywords',\n",
       "       'multimedia', 'newDesk_y', 'printPage_y', 'pubDate', 'sectionName_y',\n",
       "       'snippet', 'source', 'typeOfMaterial_y', 'webURL'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before I start the Exploratory Data Analysis (EDA), I want to eliminate some of the columns that are duplicates, or contain information that I know won't be helpful (such as URLs). Some of these columns I'm still unsure about. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['approveDate' 'commentSequence' 'commentTitle' 'parentID'\\n 'parentUserDisplayName' 'permID' 'picURL' 'updateDate' 'userDisplayName'\\n 'userID' 'userLocation' 'userTitle' 'userURL' 'inReplyTo' 'articleID'\\n 'abstract' 'articleWordCount_y' 'multimedia' 'newDesk_y' 'printPage_y'\\n 'sectionName_y' 'snippet' 'source' 'typeOfMaterial_y' 'webURL'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-99238d5fbc0f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mto_drop\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mto_drop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4161\u001b[0m                 \u001b[0mweight\u001b[0m  \u001b[1;36m1.0\u001b[0m     \u001b[1;36m0.8\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4162\u001b[0m         \"\"\"\n\u001b[1;32m-> 4163\u001b[1;33m         return super().drop(\n\u001b[0m\u001b[0;32m   4164\u001b[0m             \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4165\u001b[0m             \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   3885\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3886\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3887\u001b[1;33m                 \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3888\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3889\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[1;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[0;32m   3919\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3920\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3921\u001b[1;33m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3922\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3923\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   5280\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5281\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"ignore\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5282\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{labels[mask]} not found in axis\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5283\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5284\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['approveDate' 'commentSequence' 'commentTitle' 'parentID'\\n 'parentUserDisplayName' 'permID' 'picURL' 'updateDate' 'userDisplayName'\\n 'userID' 'userLocation' 'userTitle' 'userURL' 'inReplyTo' 'articleID'\\n 'abstract' 'articleWordCount_y' 'multimedia' 'newDesk_y' 'printPage_y'\\n 'sectionName_y' 'snippet' 'source' 'typeOfMaterial_y' 'webURL'] not found in axis\""
     ]
    }
   ],
   "source": [
    "keep = ['commentBody', 'commentID', 'commentType', 'createDate', 'depth',\n",
    "        'editorsSelection','recommendations', 'recommendedFlag', 'replyCount',\n",
    "        'reportAbuseFlag', 'sharing', 'status', 'timespeople', 'trusted','sectionName_x', \n",
    "        'newDesk_x', 'articleWordCount_x', 'printPage_x', 'typeOfMaterial_x' , 'pubDate',\n",
    "        'byline', 'documentType', 'headline', 'keywords']\n",
    "\n",
    "to_drop = [item for item in list(df.columns) if item not in keep]\n",
    "\n",
    "if print_detail:\n",
    "    print(to_drop)\n",
    "\n",
    "df.drop(to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EDA Outline\n",
    "* how many articles\n",
    "* how many comments/article\n",
    "* comment length\n",
    "\n",
    "* # of recommendations\n",
    "* relationship between recommendations and recommendation flag\n",
    "    * highly recommended comments?\n",
    "* relationship between recommendations and editorSelection\n",
    "\n",
    "* avg number of replies (replyCount)\n",
    "* relationship between replies and recommendations\n",
    "\n",
    "* number of abusive comments\n",
    "\n",
    "* sections\n",
    "    * how many articles/section\n",
    "    * how many comments/article/section\n",
    "    * comment length by section\n",
    "    * number of recommendations(or highly recommended)/section\n",
    "    * number of replies/section\n",
    "    * number of abusive comments/section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the more interesting and useful ways that the data segments itself is by section. There are several variables (sectionName, newDesk, typeOfMaterial) that might end up being best for sorting the data, so I want to take a look at each of them to see which one is most helpful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sectionName_x\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['Unknown', 'College Basketball', 'Media', 'Politics', 'Baseball',\n",
       "       'Sunday Review', 'Pro Basketball', 'Television', 'Asia Pacific',\n",
       "       'Family', 'Live', 'Education Life', 'Hockey', 'Lesson Plans',\n",
       "       'Middle East', 'Move', 'Music', 'Mind', 'Soccer', 'DealBook',\n",
       "       'Golf', 'Eat', 'Student Loans', 'Economy', 'Art & Design',\n",
       "       'Book Review', 'Europe', 'Tennis', 'Auto Racing', 'Pro Football',\n",
       "       'Canada'], dtype=object)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newDesk_x\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['Insider', 'OpEd', 'Editorial', 'Sports', 'Games', 'Culture',\n",
       "       'Travel', 'Business', 'RealEstate', 'National', 'Metro',\n",
       "       'Learning', 'Unknown', 'Foreign', 'Well', 'Upshot', 'Science',\n",
       "       'EdLife', 'Dining', 'Magazine', 'Letters', 'Arts&Leisure',\n",
       "       'Styles', 'Metropolitan', 'Weekend', 'SundayBusiness',\n",
       "       'BookReview', 'Summary'], dtype=object)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "typeOfMaterial_x\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['News', 'Op-Ed', 'Editorial', 'Review', 'Blog', 'briefing',\n",
       "       'Brief', 'Letter', 'News Analysis', 'Obituary (Obit)', 'Question'],\n",
       "      dtype=object)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# the saddest little helper function\n",
    "def print_categories(column):\n",
    "    '''the function will print the name of a given column as well as all of the categories in that column'''\n",
    "    print(column)\n",
    "    display(df[column].unique())\n",
    "\n",
    "#create a list of potential section variables\n",
    "potential_ys = ['sectionName_x', 'newDesk_x', 'typeOfMaterial_x']\n",
    "\n",
    "# print categories for each of the potential section variables\n",
    "for each in potential_ys:\n",
    "    print_categories(each)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Right now, the only columns that I'm keeping are the comment body (x) and the type of material (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>commentBody</th>\n",
       "      <th>newDesk_x</th>\n",
       "      <th>typeOfMaterial_y</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>newDesk_y</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>OpEd</th>\n",
       "      <td>82519</td>\n",
       "      <td>82519</td>\n",
       "      <td>82519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>National</th>\n",
       "      <td>37406</td>\n",
       "      <td>37406</td>\n",
       "      <td>37406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Foreign</th>\n",
       "      <td>30666</td>\n",
       "      <td>30666</td>\n",
       "      <td>30666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Editorial</th>\n",
       "      <td>24462</td>\n",
       "      <td>24462</td>\n",
       "      <td>24462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Business</th>\n",
       "      <td>20600</td>\n",
       "      <td>20600</td>\n",
       "      <td>20600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Learning</th>\n",
       "      <td>6080</td>\n",
       "      <td>6080</td>\n",
       "      <td>6080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Magazine</th>\n",
       "      <td>6049</td>\n",
       "      <td>6049</td>\n",
       "      <td>6049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Upshot</th>\n",
       "      <td>6025</td>\n",
       "      <td>6025</td>\n",
       "      <td>6025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Culture</th>\n",
       "      <td>4895</td>\n",
       "      <td>4895</td>\n",
       "      <td>4895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Metro</th>\n",
       "      <td>4613</td>\n",
       "      <td>4613</td>\n",
       "      <td>4613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Science</th>\n",
       "      <td>3268</td>\n",
       "      <td>3268</td>\n",
       "      <td>3268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Well</th>\n",
       "      <td>2809</td>\n",
       "      <td>2809</td>\n",
       "      <td>2809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dining</th>\n",
       "      <td>2560</td>\n",
       "      <td>2560</td>\n",
       "      <td>2560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sports</th>\n",
       "      <td>2495</td>\n",
       "      <td>2495</td>\n",
       "      <td>2495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Games</th>\n",
       "      <td>2169</td>\n",
       "      <td>2169</td>\n",
       "      <td>2169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SundayBusiness</th>\n",
       "      <td>1607</td>\n",
       "      <td>1607</td>\n",
       "      <td>1607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EdLife</th>\n",
       "      <td>1185</td>\n",
       "      <td>1185</td>\n",
       "      <td>1185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Travel</th>\n",
       "      <td>1088</td>\n",
       "      <td>1088</td>\n",
       "      <td>1088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RealEstate</th>\n",
       "      <td>784</td>\n",
       "      <td>784</td>\n",
       "      <td>784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Insider</th>\n",
       "      <td>664</td>\n",
       "      <td>664</td>\n",
       "      <td>664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Weekend</th>\n",
       "      <td>484</td>\n",
       "      <td>484</td>\n",
       "      <td>484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Styles</th>\n",
       "      <td>371</td>\n",
       "      <td>371</td>\n",
       "      <td>371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Arts&amp;Leisure</th>\n",
       "      <td>331</td>\n",
       "      <td>331</td>\n",
       "      <td>331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Metropolitan</th>\n",
       "      <td>263</td>\n",
       "      <td>263</td>\n",
       "      <td>263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BookReview</th>\n",
       "      <td>221</td>\n",
       "      <td>221</td>\n",
       "      <td>221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unknown</th>\n",
       "      <td>178</td>\n",
       "      <td>178</td>\n",
       "      <td>178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Letters</th>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Summary</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                commentBody  newDesk_x  typeOfMaterial_y\n",
       "newDesk_y                                               \n",
       "OpEd                  82519      82519             82519\n",
       "National              37406      37406             37406\n",
       "Foreign               30666      30666             30666\n",
       "Editorial             24462      24462             24462\n",
       "Business              20600      20600             20600\n",
       "Learning               6080       6080              6080\n",
       "Magazine               6049       6049              6049\n",
       "Upshot                 6025       6025              6025\n",
       "Culture                4895       4895              4895\n",
       "Metro                  4613       4613              4613\n",
       "Science                3268       3268              3268\n",
       "Well                   2809       2809              2809\n",
       "Dining                 2560       2560              2560\n",
       "Sports                 2495       2495              2495\n",
       "Games                  2169       2169              2169\n",
       "SundayBusiness         1607       1607              1607\n",
       "EdLife                 1185       1185              1185\n",
       "Travel                 1088       1088              1088\n",
       "RealEstate              784        784               784\n",
       "Insider                 664        664               664\n",
       "Weekend                 484        484               484\n",
       "Styles                  371        371               371\n",
       "Arts&Leisure            331        331               331\n",
       "Metropolitan            263        263               263\n",
       "BookReview              221        221               221\n",
       "Unknown                 178        178               178\n",
       "Letters                  32         32                32\n",
       "Summary                   8          8                 8"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(by='newDesk_x').count()\n",
    "df.groupby(by='newDesk_y').count().sort_values('commentBody', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>commentBody</th>\n",
       "      <th>newDesk_x</th>\n",
       "      <th>typeOfMaterial_y</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>newDesk_y</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Arts&amp;Leisure</th>\n",
       "      <td>331</td>\n",
       "      <td>331</td>\n",
       "      <td>331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BookReview</th>\n",
       "      <td>221</td>\n",
       "      <td>221</td>\n",
       "      <td>221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Business</th>\n",
       "      <td>20600</td>\n",
       "      <td>20600</td>\n",
       "      <td>20600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Culture</th>\n",
       "      <td>4895</td>\n",
       "      <td>4895</td>\n",
       "      <td>4895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dining</th>\n",
       "      <td>2560</td>\n",
       "      <td>2560</td>\n",
       "      <td>2560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EdLife</th>\n",
       "      <td>1185</td>\n",
       "      <td>1185</td>\n",
       "      <td>1185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Editorial</th>\n",
       "      <td>24462</td>\n",
       "      <td>24462</td>\n",
       "      <td>24462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Foreign</th>\n",
       "      <td>30666</td>\n",
       "      <td>30666</td>\n",
       "      <td>30666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Games</th>\n",
       "      <td>2169</td>\n",
       "      <td>2169</td>\n",
       "      <td>2169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Insider</th>\n",
       "      <td>664</td>\n",
       "      <td>664</td>\n",
       "      <td>664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Learning</th>\n",
       "      <td>6080</td>\n",
       "      <td>6080</td>\n",
       "      <td>6080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Letters</th>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Magazine</th>\n",
       "      <td>6049</td>\n",
       "      <td>6049</td>\n",
       "      <td>6049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Metro</th>\n",
       "      <td>4613</td>\n",
       "      <td>4613</td>\n",
       "      <td>4613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Metropolitan</th>\n",
       "      <td>263</td>\n",
       "      <td>263</td>\n",
       "      <td>263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>National</th>\n",
       "      <td>37406</td>\n",
       "      <td>37406</td>\n",
       "      <td>37406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OpEd</th>\n",
       "      <td>82519</td>\n",
       "      <td>82519</td>\n",
       "      <td>82519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RealEstate</th>\n",
       "      <td>784</td>\n",
       "      <td>784</td>\n",
       "      <td>784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Science</th>\n",
       "      <td>3268</td>\n",
       "      <td>3268</td>\n",
       "      <td>3268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sports</th>\n",
       "      <td>2495</td>\n",
       "      <td>2495</td>\n",
       "      <td>2495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Styles</th>\n",
       "      <td>371</td>\n",
       "      <td>371</td>\n",
       "      <td>371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Summary</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SundayBusiness</th>\n",
       "      <td>1607</td>\n",
       "      <td>1607</td>\n",
       "      <td>1607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Travel</th>\n",
       "      <td>1088</td>\n",
       "      <td>1088</td>\n",
       "      <td>1088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unknown</th>\n",
       "      <td>178</td>\n",
       "      <td>178</td>\n",
       "      <td>178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Upshot</th>\n",
       "      <td>6025</td>\n",
       "      <td>6025</td>\n",
       "      <td>6025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Weekend</th>\n",
       "      <td>484</td>\n",
       "      <td>484</td>\n",
       "      <td>484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Well</th>\n",
       "      <td>2809</td>\n",
       "      <td>2809</td>\n",
       "      <td>2809</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                commentBody  newDesk_x  typeOfMaterial_y\n",
       "newDesk_y                                               \n",
       "Arts&Leisure            331        331               331\n",
       "BookReview              221        221               221\n",
       "Business              20600      20600             20600\n",
       "Culture                4895       4895              4895\n",
       "Dining                 2560       2560              2560\n",
       "EdLife                 1185       1185              1185\n",
       "Editorial             24462      24462             24462\n",
       "Foreign               30666      30666             30666\n",
       "Games                  2169       2169              2169\n",
       "Insider                 664        664               664\n",
       "Learning               6080       6080              6080\n",
       "Letters                  32         32                32\n",
       "Magazine               6049       6049              6049\n",
       "Metro                  4613       4613              4613\n",
       "Metropolitan            263        263               263\n",
       "National              37406      37406             37406\n",
       "OpEd                  82519      82519             82519\n",
       "RealEstate              784        784               784\n",
       "Science                3268       3268              3268\n",
       "Sports                 2495       2495              2495\n",
       "Styles                  371        371               371\n",
       "Summary                   8          8                 8\n",
       "SundayBusiness         1607       1607              1607\n",
       "Travel                 1088       1088              1088\n",
       "Unknown                 178        178               178\n",
       "Upshot                 6025       6025              6025\n",
       "Weekend                 484        484               484\n",
       "Well                   2809       2809              2809"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(by='newDesk_y').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test run for processing a single string - want to functionalize\n",
    "#integers = []\n",
    "\n",
    "def lower_and_sw_filter(comment_str):\n",
    "    ''' this function returns a string with all the characters converted to lowercase\n",
    "    and all stopwords and punctuation removed'''\n",
    "    \n",
    "    #strip html tags\n",
    "    comment_str = strip_tags(comment_str)\n",
    "    \n",
    "    #lowercase\n",
    "    comment_str = comment_str.lower()\n",
    "\n",
    "    #tokenize\n",
    "    tokenizer = RegexpTokenizer(r'[a-zA-Z0-9]+')\n",
    "\n",
    "    comment_str = tokenizer.tokenize(comment_str)\n",
    "\n",
    "    #stopwords\n",
    "\n",
    "    filtered = list(filter(lambda x: x.lower() not in stopwords_set, comment_str))\n",
    "\n",
    "    #lemmatize\n",
    "\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemma = []\n",
    "    for word in filtered:\n",
    "#         #print(word)\n",
    "#         if word.isdigit():\n",
    "#             int_list.append(word)\n",
    "        \n",
    "        lemmatized_word = lemmatizer.lemmatize(word)\n",
    "        lemma.append(lemmatized_word)\n",
    "    \n",
    "    lemma = ' '.join(lemma)\n",
    "    \n",
    "    return lemma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "265.8px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
